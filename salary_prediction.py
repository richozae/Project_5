# -*- coding: utf-8 -*-
"""Salary_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Nr57s6ep9IXaMUTWuI_RVEZsVLZ75r_n

RICHO
"""

#importing the libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/progresproject/posting/Salary_Prediction.csv')

"""Data Pre-processing"""

df.head()

df.tail()

df.isnull().sum()

df.dropna(axis=0, inplace=True)

#checking for null values
df.isnull().sum()

#dropping column
df.drop(columns = 'Unnamed: 0',axis=1,inplace=True)

df.dtypes

#unique values in each column
df.nunique()

"""Grouping Job Titles"""

df['Job Title'].unique()

def categorize_job_title(job_title):
    job_title = str(job_title).lower()
    if 'software' in job_title or 'developer' in job_title:
        return 'Software/Developer'
    elif 'data' in job_title or 'analyst' in job_title or 'scientist' in job_title:
        return 'Data Analyst/Scientist'
    elif 'manager' in job_title or 'director' in job_title or 'vp' in job_title:
        return 'Manager/Director/VP'
    elif 'sales' in job_title or 'representative' in job_title:
        return 'Sales'
    elif 'marketing' in job_title or 'social media' in job_title:
        return 'Marketing/Social Media'
    elif 'product' in job_title or 'designer' in job_title:
        return 'Product/Designer'
    elif 'hr' in job_title or 'human resources' in job_title:
        return 'HR/Human Resources'
    elif 'financial' in job_title or 'accountant' in job_title:
        return 'Financial/Accountant'
    elif 'project manager' in job_title:
        return 'Project Manager'
    elif 'it' in job_title or 'support' in job_title:
        return 'IT/Technical Support'
    elif 'operations' in job_title or 'supply chain' in job_title:
        return 'Operations/Supply Chain'
    elif 'customer service' in job_title or 'receptionist' in job_title:
        return 'Customer Service/Receptionist'
    else:
        return 'Other'

df['Job Title'] = df['Job Title'].apply(categorize_job_title)

df['Education Level'].unique()

"""Grouping Education Level"""

def group_education(Educaton):

    Educaton = str(Educaton).lower()
    if 'high school' in Educaton:
        return 'High School'
    elif 'bachelor\'s' in Educaton:
        return 'Bachelors'
    elif 'master\'s' in Educaton:
        return 'Masters'
    elif 'phd' in Educaton:
        return 'PhD'

df['Education Level'] = df['Education Level'].apply(group_education)

"""Descriptive Statstics"""

#descriptive statistics for parameter statistic ex: count, mean, and more
df.describe()

"""Exploratory Data Analysis"""

#pie chart
plt.figure(figsize=(10,6))
plt.pie(df['Gender'].value_counts(), labels=['Male','Female', 'Other'], autopct='%1.1f%%', startangle=100)
plt.title('Gender Distribution')
plt.show()

"""Based on the circle diagram above, the majority are men with a percentage reaching 54.8%

Age Distribution
"""

sns.histplot(data=df, x='Age', bins=20, kde=True)
plt.title('Age Distribution')
plt.show()

"""Based on the histogram diagram above, it can be seen that the average age is mostly in the range of 25 to 30 years. while the 60 range is the lowest age."""

sns.countplot(x = 'Education Level', data = df, palette='Set1')
plt.xticks(rotation=90)

"""Most of the employees have a Bachelor's degree, followed by a Master's degree and a Doctoral degree. The least number of employees have a High School education. From the graph, it is evident that the majority of employees started working after graduating, with a few commencing their careers after completing their Master's degree.

Job Title
"""

sns.countplot(x='Job Title', data = df)
plt.xticks(rotation=90)

"""From this graph, it's clear that the majority of employees have job titles such as Software Developer, Data Analyst/Scientist, or Manager/Director/VP. The number of employees with job titles like sales, marketing/social media, HR, Product Designer, and Customer Service is less. Very few employees work as Financial/Accountant or Operation/Supply Management.

From this, I hypothesize that job titles like Software Developer, Data Analyst/Scientist, and Manager/Director are more in demand compared to other job titles.

Years of Experience
"""

sns.histplot(x = 'Years of Experience', data = df,kde=True)

"""Based on the histogram above, it is found that the most dominant work experience is 3 to 5 years. while 35 years of work experience yields the least value.

Country
"""

sns.countplot(x='Country', data=df)
plt.xticks(rotation=90)

"""Racial Distribution"""

sns.countplot(x='Race', data=df)
plt.xticks(rotation=90)

"""This graph helps us understand the racial distribution in the dataset. From the graph, it's evident that the majority of employees are either White or Asian, followed by Koreans, Chinese, Australians, and Black individuals. The number of employees from Welsh, African American, Mixed, and Hispanic racial backgrounds is smaller compared to other groups.

From all the plots and graphs above, we gain insights into the data we are working with, its distribution, and its quantity. Now, I will explore the relationships between these independent variables and the target variable, which is Salary.

Age and Salary
"""

sns.scatterplot(x = 'Age', y='Salary', data=df)
plt.title('Age vs Salary')

"""In this scatter plot we see a trend that a person's salary increases with age, which is clearly visible due to promotions and appraisals. However, if we look closely we can find that the same age has double the salary, which means there are other factors that determine the salary. Based on the scatter plot graph above, the graphic pattern relationship produces a positive correlation relationship, which means there is a relationship between salary and age

Gender and Salary
"""

fig, ax = plt.subplots(1,2, figsize = (12, 5))
sns.boxplot(x = 'Gender', y='Salary', data = df, ax =ax[0]).set_title('Gender vs Salary')
sns.violinplot(x = 'Gender', y='Salary', data = df, ax =ax[1]).set_title('Gender vs Salary')

"""The boxplot and violinplot illustrate the salary distribution across the three genders. In the boxplot, employees of the "Other" gender tend to have higher salaries compared to males and females. Specifically, the "Other" gender employees have a median salary exceeding 150,000, followed by males with a median salary close to 107,500, and females with a median salary around 100,000.

The violin plot provides a visual representation of salary distribution by gender. For employees of the "Other" gender, the majority have salaries above 150,000. Among males, the distribution is concentrated between 50,000 and 100,000, as well as around 200,000. In the case of females, their salary distribution is relatively more dispersed compared to the other genders, with a significant portion near 50,000.

Education and Salary
"""

fig,ax = plt.subplots(1,2,figsize=(12,6))
sns.boxplot(x = 'Education Level', y = 'Salary', data = df, ax=ax[0]).set_title('Education Level vs Salary')
sns.violinplot(x = 'Education Level', y = 'Salary', data = df, ax=ax[1]).set_title('Education Level vs Salary')

"""The boxplot and violinplot shows the distribution of salary based on the employees education level. The median salary for the Phd holders is highest followed by Masters and bachelors degreee holders, with employees with no degree having the lowest median salary. In the violinplot the phd scholars have distribution near 200000, whereas Masters degree holders have a very sleak distribution where the salary distribution is spread from 100k to 150k, The Bachelors degree holders have a salary distribution near 50000 whereas the employees with no degree have a salary distribution near 40k-45k.

From these graph, I assume that the employees with higher education level have higher salary than the employees with lower education level.

Job Title and Salary
"""

sns.barplot(x = 'Job Title', y = 'Salary', data = df, palette = 'Set2')
plt.xticks(rotation = 90)

"""This graph challenges my previous hypothesis regarding the demand and salary levels associated with job titles. Contrary to my earlier assumption, the "Other" category of job titles tends to have higher salaries compared to those titles that were presumed to be in high demand and well-paying. Unlike the previous job title graph, this graph suggests that there is no clear relationship between the distribution of job titles and salary. Surprisingly, some job titles that offer high salaries are relatively less common.

However, the hypothesis holds true for job titles such as Software Developer, Data Analyst/Scientist, and Manager/Director/VP, which are indeed in high demand and come with competitive salaries. On the other hand, job titles like Operation/Supply Chain, HR, Financial/Accountant, and Marketing/Social Media appear to have significantly higher salaries than initially assumed.

In summary, while there are exceptions, this graph highlights that the relationship between job titles, their distribution, and salaries can be more complex than initially perceived.

Experience and Salary
"""

sns.scatterplot(x= 'Years of Experience', y  = 'Salary', data = df).set_title('Years of Experience vs Salary')

"""Based on the above scatter plot, a positive correlation is observed between salary and years of experience. The longer the work experience, the higher the likelihood of obtaining a larger salary.

Country and Salary
"""

fig,ax = plt.subplots(1,2,figsize=(12,5))
sns.boxplot(x = 'Country', y = 'Salary', data = df, ax=ax[0])
sns.violinplot(x = 'Country', y = 'Salary', data = df, ax=ax[1])

fig,ax = plt.subplots(3,2,figsize=(20,20))
plt.subplots_adjust(hspace=0.5)
sns.boxplot(x = 'Job Title', y = 'Salary', data = df[df['Country'] == 'USA'], ax = ax[0,0]).set_title('USA')
ax[0,0].tick_params(axis='x', rotation=90)
sns.boxplot(x = 'Job Title', y = 'Salary', data = df[df['Country'] == 'UK'], ax = ax[0,1]).set_title('UK')
ax[0,1].tick_params(axis='x', rotation=90)
sns.boxplot(x = 'Job Title', y = 'Salary', data = df[df['Country'] == 'Canada'], ax = ax[1,0]).set_title('Canada')
ax[1,0].tick_params(axis='x', rotation=90)
sns.boxplot(x = 'Job Title', y = 'Salary', data = df[df['Country'] == 'Australia'], ax = ax[1,1]).set_title('Australia')
ax[1,1].tick_params(axis='x', rotation=90)
sns.boxplot(x = 'Job Title', y = 'Salary', data = df[df['Country'] == 'China'], ax = ax[2,0]).set_title('China')
ax[2,0].tick_params(axis='x', rotation=90)
sns.boxplot(x = 'Job Title', y = 'Salary', data = df, ax = ax[2,1]).set_title('All Countries')
ax[2,1].tick_params(axis='x', rotation=90)

"""Race and Salary"""

fig,ax = plt.subplots(1,2,figsize=(15,6))
sns.boxplot(x = 'Race', y = 'Salary', data = df, ax = ax[0])
ax[0].tick_params(axis='x', rotation=90)
sns.violinplot(x = 'Race', y ='Salary', data = df, ax = ax[1])
ax[1].tick_params(axis='x', rotation=90)

"""Data Preprocessing 2

Label encoding to categorical features
"""

from sklearn.preprocessing import LabelEncoder
features = ['Gender','Country','Education Level','Job Title', 'Race']
le = LabelEncoder()
for feature in features:
    le.fit(df[feature].unique())
    df[feature] = le.transform(df[feature])
    print(feature, df[feature].unique())

"""Normalization"""

#normalizing the continuous variables
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[['Age', 'Years of Experience', 'Salary']] = scaler.fit_transform(df[['Age', 'Years of Experience', 'Salary']])

df.head()

"""Corelation Matrix Heatmap"""

#coorelation heatmap
plt.figure(figsize=(12,8))
sns.heatmap(df.corr(),annot=True, cmap='coolwarm')

"""Based on the heatmap correlation above, it is found that there is a correlation between years of experience and age, salary and years experience, and age and salary.

Train and Test Split
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df.drop('Salary', axis=1), df['Salary'], test_size=0.2, random_state=42)

"""Decision Tree"""

from sklearn.tree import DecisionTreeRegressor

#createing the decision tree gressor object
dtree = DecisionTreeRegressor()

"""Hypertuning the model"""

from sklearn.model_selection import GridSearchCV

#defining the parameters for the grid search
parameters = {'max_depth' :[2,4,6,8,10],
              'min_samples_split' :[2,4,6,8],
              'min_samples_leaf' :[2,4,6,8],
              'max_features' :['auto','sqrt','log2'],
              'random_state' :[0,42]}
#creating the grid search object
grid_search = GridSearchCV(dtree,parameters,cv=5,scoring='neg_mean_squared_error',n_jobs=-1)

#fit the grid search object to the training data
grid_search.fit(X_train,y_train)

#print the best parameters
print(grid_search.best_params_)

dtree = DecisionTreeRegressor(max_depth = 10, max_features = 'auto', min_samples_leaf = 2, min_samples_split = 8, random_state = 42)
dtree

#fitting the training data
dtree.fit(X_train,y_train)

#training accuracy
dtree.score(X_train, y_train)

#predicting the salary of an employee
d_pred = dtree.predict(X_test)

"""Evaluating the Decision Tree"""

dft = pd.DataFrame({'Actual': y_test, 'Predicted': d_pred})
dft.reset_index(drop=True, inplace=True)
dft.head(10)

ax = sns.distplot(dft['Actual'], color = 'blue', hist = False, kde = True, kde_kws = {'linewidth': 3}, label = 'Actual')
sns.distplot(  dft['Predicted'], color = 'red', ax=ax, hist = False, kde = True, kde_kws = {'linewidth': 3}, label = 'Predicted')

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
print("R2 Score: ", r2_score(y_test, d_pred))
print("Mean Squared Error: ", mean_squared_error(y_test, d_pred))
print("Mean Absolute Error: ", mean_absolute_error(y_test, d_pred))
print('RMSE:', np.sqrt(mean_squared_error(y_test, d_pred)))

"""Random Forest Regressor"""

from sklearn.ensemble import RandomForestRegressor
#creating random forest regressor object
rfg = RandomForestRegressor()

#trainig the model
rfg.fit(X_train, y_train)

#training accuracy
rfg.score(X_train, y_train)

#predicitng salary of the employee
r_pred = rfg.predict(X_test)

"""Evaluating Random Forest Regressor Model"""

dfr = pd.DataFrame({'Actual': y_test, 'Predicted': r_pred})
dfr.reset_index(drop=True, inplace=True)
dfr.head(10)

ax = sns.distplot(dft['Actual'], color = 'blue', hist = False, kde = True, kde_kws = {'linewidth': 3}, label = 'Actual')
sns.distplot(  dft['Predicted'], color = 'red', ax=ax, hist = False, kde = True, kde_kws = {'linewidth': 3}, label = 'Predicted')

print("R2 Score: ", r2_score(y_test, r_pred))
print("Mean Squared Error: ", mean_squared_error(y_test, r_pred))
print("Mean Absolute Error: ", mean_absolute_error(y_test, r_pred))
print('RMSE:', np.sqrt(mean_squared_error(y_test, r_pred)))

# Make count diagram
# Akurasi  Decision Tree
dtree_accuracy = dtree.score(X_train, y_train)

# Akurasi RandomForestRegressor
rfg_accuracy = rfg.score(X_train, y_train)

labels = ['Decision Tree', 'RandomForestRegressor']
accuracy_scores = [dtree_accuracy, rfg_accuracy]

plt.bar(labels, accuracy_scores)
plt.xlabel('Model')
plt.ylabel('Accuracy Score')
plt.title('Training Accuracy Comparison')
plt.show()

"""# Conclusion
Based on data analysis, we can conclude that the amount of employee salaries is influenced by several main factors, namely:
1. Education Level
2. Position
3. Age
4. Years of Experience

From the comparison between the Decision Tree and Random Forest Regressor methods, the results show that the Random Forest Regressor produces a higher level of accuracy than the Decision Tree. In this case, the accuracy of the Random Forest Regressor reaches 98.78%, while the Decision Tree reaches 96.56%.
"""